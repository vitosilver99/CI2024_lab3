{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Copyright **`(c)`** 2024 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free under certain conditions — see the [`license`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from random import choice\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from heapq import heappush, heappop\n",
    "from icecream import ic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUZZLE_DIM = 3\n",
    "action = namedtuple('Action', ['pos1', 'pos2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "COST = 0\n",
    "\n",
    "def available_actions(state: np.ndarray) -> list['Action']:\n",
    "    x, y = [int(_[0]) for _ in np.where(state == 0)]\n",
    "    actions = list()\n",
    "    if x > 0:\n",
    "        actions.append(action((x, y), (x - 1, y)))\n",
    "    if x < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        actions.append(action((x, y), (x, y - 1)))\n",
    "    if y < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x, y + 1)))\n",
    "    return actions\n",
    "\n",
    "\n",
    "\n",
    "def do_action(state: np.ndarray, action: 'Action') -> np.ndarray:\n",
    "    global COST\n",
    "    COST += 1\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Randomizing: 100%|██████████| 100000/100000 [00:00<00:00, 164257.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 8],\n",
       "       [5, 7, 1],\n",
       "       [6, 3, 4]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOMIZE_STEPS = 100_000\n",
    "state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "for r in tqdm(range(RANDOMIZE_STEPS), desc='Randomizing'):\n",
    "    state = do_action(state, choice(available_actions(state)))\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 8],\n",
       "       [5, 7, 1],\n",
       "       [6, 3, 4]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to calculate the Manhattan distance relative to the map\n",
    "def heuristic(state, goal_positions):\n",
    "        dist = 0\n",
    "        for i in range(PUZZLE_DIM):\n",
    "            for j in range(PUZZLE_DIM):\n",
    "                if state[i, j] != 0:\n",
    "                    goal_x, goal_y = goal_positions[state[i, j]]\n",
    "                    # Sum of vertical and horizontal distances between the tile and its goal position\n",
    "                    dist += abs(i - goal_x) + abs(j - goal_y)\n",
    "        return dist\n",
    "\n",
    "\n",
    "def a_star(initial_state: np.ndarray, goal_state: np.ndarray):\n",
    "    global COST \n",
    "    COST = 0\n",
    "    # Create a map of the goal positions\n",
    "    goal_positions = {value: divmod(idx, PUZZLE_DIM) for idx, value in enumerate(goal_state.flatten())}\n",
    "\n",
    "    open_set = []  # Priority queue\n",
    "    came_from = {}  # Tracks where states came from\n",
    "    visited = set()  # Already visited states\n",
    "\n",
    "    # Initialize the queue with the initial state\n",
    "    heappush(open_set, (0, initial_state.tobytes()))  # (f, state)\n",
    "    g_score = {initial_state.tobytes(): 0}  # Cost to reach the states\n",
    "\n",
    "    while open_set:\n",
    "        # Extract the state with the lowest score\n",
    "        _, current_bytes = heappop(open_set)\n",
    "\n",
    "        # Skip already visited states\n",
    "        if current_bytes in visited:\n",
    "            continue\n",
    "\n",
    "        # Add the current state to the visited set\n",
    "        visited.add(current_bytes)\n",
    "\n",
    "        # Convert the byte array back to the current state\n",
    "        current_state = np.frombuffer(current_bytes, dtype=int).reshape(PUZZLE_DIM, PUZZLE_DIM)\n",
    "\n",
    "        # Check if the current state is the goal state\n",
    "        if np.array_equal(current_state, goal_state):\n",
    "            # Reconstruct the path\n",
    "            path = []\n",
    "            while current_bytes in came_from:\n",
    "                current_bytes, action = came_from[current_bytes]\n",
    "                path.append(action)\n",
    "            return path[::-1], COST  # Reverse the path to get the solution\n",
    "\n",
    "        # Explore the neighbors\n",
    "        for action in available_actions(current_state):\n",
    "            neighbor = do_action(current_state, action)\n",
    "            neighbor_bytes = neighbor.tobytes()\n",
    "\n",
    "            # Skip already visited states\n",
    "            if neighbor_bytes in visited:\n",
    "                continue\n",
    "\n",
    "            # Calculate the new cost\n",
    "            tentative_g_score = g_score[current_bytes] + 1\n",
    "\n",
    "            # Update the data if a better path is found\n",
    "            if tentative_g_score < g_score.get(neighbor_bytes, float('inf')):\n",
    "                came_from[neighbor_bytes] = (current_bytes, action)\n",
    "                g_score[neighbor_bytes] = tentative_g_score\n",
    "                f_score = tentative_g_score + heuristic(neighbor, goal_positions)\n",
    "                heappush(open_set, (f_score, neighbor_bytes))\n",
    "\n",
    "    # Return None if no solution is found\n",
    "    return None\n",
    "\n",
    "\n",
    "def greedy_best_first_search(initial_state: np.ndarray, goal_state: np.ndarray, max_depth: int = 200) -> int:\n",
    "    global COST\n",
    "    COST = 0\n",
    "    \n",
    "    goal_positions = {value: divmod(idx, PUZZLE_DIM) for idx, value in enumerate(goal_state.flatten())}\n",
    "\n",
    "    # Initialize the priority queue (open_set)\n",
    "    open_set = []\n",
    "    visited = set()  # Already visited states\n",
    "    heappush(open_set, (heuristic(initial_state, goal_positions), 0, initial_state.tobytes()))  # (heuristic, depth, state)\n",
    "    \n",
    "    # Main loop\n",
    "    while open_set:\n",
    "        _, depth, current_bytes = heappop(open_set)\n",
    "\n",
    "        if current_bytes in visited:\n",
    "            continue\n",
    "        visited.add(current_bytes)  # Add the current state to the visited set\n",
    "\n",
    "        current_state = np.frombuffer(current_bytes, dtype=int).reshape(PUZZLE_DIM, PUZZLE_DIM)\n",
    "\n",
    "        # If the goal state is reached, return the number of steps (depth)\n",
    "        if np.array_equal(current_state, goal_state):\n",
    "            return depth, current_state, COST\n",
    "\n",
    "        # Check if we have exceeded the maximum depth\n",
    "        if depth >= max_depth:\n",
    "            continue\n",
    "\n",
    "        # Explore the neighbors\n",
    "        for action in available_actions(current_state):\n",
    "            neighbor = do_action(current_state, action)\n",
    "            neighbor_bytes = neighbor.tobytes()\n",
    "\n",
    "            if neighbor_bytes not in visited:  # Explore only unvisited states\n",
    "                # Add the neighbor to the queue with an incremented depth\n",
    "                heappush(open_set, (heuristic(neighbor, goal_positions), depth + 1, neighbor_bytes))\n",
    "            \n",
    "    print(\"No solution found within the specified depth limit.\")\n",
    "    return -1  # Indicates that the solution was not found\n",
    "\n",
    "\n",
    "# Initial state and goal state\n",
    "initial_state_greedy = initial_state_a_star = state\n",
    "goal_state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution found in 48 steps with a cost of: 931 using Greedy Best-First Search\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 0]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedy_num_steps, current_state, cost = greedy_best_first_search(initial_state_greedy, goal_state)\n",
    "print(f\"Solution found in {greedy_num_steps} steps with a cost of: {cost} using Greedy Best-First Search\")\n",
    "current_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution found in 22 steps with a cost of: 429 using A*\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 0]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution_a_star, cost = a_star(initial_state_a_star, goal_state)\n",
    "for s in solution_a_star: \n",
    "    initial_state_a_star = do_action(initial_state_a_star, s)\n",
    "\n",
    "print(f\"Solution found in {len(solution_a_star)} steps with a cost of: {cost} using A*\")\n",
    "initial_state_a_star\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
